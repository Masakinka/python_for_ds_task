{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masakinka/python_for_ds_task/blob/main/%D0%92%D0%B8%D0%BA%D0%BE%D1%80%D0%B8%D1%81%D1%82%D0%B0%D0%BD%D0%BD%D1%8F_%D0%BF%D1%80%D0%BE%D0%BC%D0%BF%D1%82%D1%96%D0%B2_%D1%96_%D0%B0%D0%B3%D0%B5%D0%BD%D1%82%D1%96%D0%B2_%D0%B2_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Завдання 1: Виклик LLM з базовим промптом\n",
        "\n",
        "Створіть можливість викликати LLM зі звичайним текстовим промптом.\n",
        "\n",
        "Промпт має дозвляти отримати інформацію простою мовою на певну тему. В цьому завданні ми хочемо дізнатись про тему \"Квантові обчислення\".\n",
        "\n",
        "Відповідь моделі повинна містити визначення, ключові переваги та поточні дослідження в цій галузі.\n",
        "\n",
        "Обмежте відповідь до 200 символів і пропишіть в промпті аби відповідь була короткою (це зекономить Вам час і гроші на згенеровані токени).\n",
        "\n",
        "В якості LLM можна скористатись як моделлю з HugginFace (рекомендую Mistral), так і ChatGPT4 або ChatGPT3. В обох випадках треба імпортувати потрібну \"обгортку\" (тобто клас, який дозволить ініціювати модель) з LangChain для виклику LLM за API, а також зчитати особистий токен з файла, наприклад, `creds.json`, який розміщений у Вас локально і Ви НЕ здаєте його в ДЗ і НЕ комітите в git 😏\n",
        "\n",
        "Встановіть своє значення температури на свій розсуд (тут немає правильного чи неправильного значення) і напишіть, чому ви обрали саме таке значення для цього завдання.  \n",
        "\n",
        "Запити можна робити як українською, так і англійською - орієнтуйтесь на те, де і чи хочете ви потім лишити цей проєкт і відповідна яка мова буде пасувати більше. В розвʼязках промпти - українською."
      ],
      "metadata": {
        "id": "RMalK_oYR-X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tNQRKQ4H8BZ",
        "outputId": "27fcf094-b253-4bfe-dd16-3bd099a53233"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RRYSu48huSUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8e109431-eefd-4c01-a939-913cfea4d55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain langchain_community huggingface_hub openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vT1ICe74cAUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295f1ed0-8a1a-4cc2-e7a0-b62a7f160b8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "yXXbub0aGv1I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creds_path = '/content/drive/MyDrive/Colab Notebooks/creds/creds.json'\n",
        "\n",
        "# Read creds.json\n",
        "with open(creds_path, 'r') as f:\n",
        "    creds = json.load(f)\n",
        "\n",
        "api_key = creds[\"openai_api_key\"]"
      ],
      "metadata": {
        "id": "niLO41FjGyQD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model using the API key with a temperature of 0.3 for less randomness\n",
        "llm = OpenAI(api_key=api_key, temperature=0.3)\n",
        "\n",
        "# Example prompt asking for a brief answer on the topic of quantum computing\n",
        "prompt = \"\"\"\n",
        "Квантові обчислення: визначення, ключові переваги та поточні дослідження в галузі.\n",
        "Коротко і до 200 символів, будь ласка.\n",
        "\"\"\"\n",
        "\n",
        "# Get the model's response\n",
        "response = llm(prompt)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzR6IKP8Hs8q",
        "outputId": "60034296-5dbb-4c8c-9a60-0cffae7b4221"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Квантові обчислення - це обчислювальна технологія, яка використовує квантові біти замість класичних бітів для виконання обчислень. Вони мають потенціал вирішувати складні задачі швидше, ефективніше та з більшою точністю, ніж класичні комп'ютери. Квантові обчислення можуть бути застосовані в багатьох галузях, таких як криптографія, хімія, фізика та штучний інтелект. Поточні дослідження в цій галузі спрямовані на розробку більш потужни\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Обираю температуру 0.3, тому що це значення забезпечує баланс між креативністю та точністю. Для завдання, де потрібна коротка, інформативна відповідь без відхилень від теми, низьке значення температури (наприклад, 0.3) дозволяє мінімізувати випадкові варіації у відповідях, зберігаючи при цьому чіткість та структурованість."
      ],
      "metadata": {
        "id": "LB43_epwLoXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 2: Створення параметризованого промпта для генерації тексту\n",
        "Тепер ми хочемо оновити попередній фукнціонал так, аби в промпт ми могли передавати тему як параметр. Для цього скористайтесь `PromptTemplate` з `langchain` і реалізуйте параметризований промпт та виклик моделі з ним.\n",
        "\n",
        "Запустіть оновлений функціонал (промпт + модел) для пояснень про теми\n",
        "- \"Баєсівські методи в машинному навчанні\"\n",
        "- \"Трансформери в машинному навчанні\"\n",
        "- \"Explainable AI\"\n",
        "\n",
        "Виведіть результати відпрацювання моделі на екран."
      ],
      "metadata": {
        "id": "UiIzV0UIS0GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Prompt Template\n",
        "template = \"\"\"\n",
        "Поясніть тему \"{topic}\" простими словами. Будь ласка, дайте коротке пояснення.\n",
        "\"\"\"\n",
        "\n",
        "# Create a PromptTemplate object with the \"topic\" parameter\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=template,\n",
        ")"
      ],
      "metadata": {
        "id": "kcg7EfdNcBDq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Topics to explain\n",
        "topics = [\n",
        "    \"Баєсовські методи в машинному навчанні\",\n",
        "    \"Трансформери в машинному навчанні\",\n",
        "    \"Explainable AI\"\n",
        "]\n",
        "\n",
        "# Loop to generate explanations for each topic\n",
        "for topic in topics:\n",
        "    # Generate prompt using parameter\n",
        "    prompt = prompt_template.format(topic=topic)\n",
        "\n",
        "    # Getting response from model\n",
        "    response = llm(prompt)\n",
        "\n",
        "    # Output the result\n",
        "    print(f\"Тема: {topic}\\nОтвет: {response}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3ij9TkjMtPT",
        "outputId": "5cf4de77-1dd5-4d1f-efde-0fbbfc521b31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тема: Баєсовські методи в машинному навчанні\n",
            "Ответ: \n",
            "Баєсовські методи в машинному навчанні - це підхід до розв'язання задач штучного інтелекту, який базується на теорії ймовірності і використовує статистичні методи для прийняття рішень. Вони дозволяють моделювати невизначеність і неоднозначність в даних та враховувати нову інформацію, що з'являється під час навчання. Це дозволяє покращити якість прогнозів і зробити більш точні рішення. \n",
            "\n",
            "Тема: Трансформери в машинному навчанні\n",
            "Ответ: \n",
            "Трансформери - це алгоритми, які використовуються в машинному навчанні для обробки текстової інформації. Вони дозволяють моделям зосередитися на важливих частинах тексту та зрозуміти зв'язки між словами. Це допомагає покращити якість розпізнавання тексту та зробити моделі більш точними. \n",
            "\n",
            "Тема: Explainable AI\n",
            "Ответ: \n",
            "Explainable AI - це підхід до створення штучного інтелекту, який дозволяє зрозуміти причини прийняття рішень та дій штучної системи. Це означає, що алгоритми штучного інтелекту повинні бути зрозумілі та пояснені людям, щоб вони могли довіряти та контролювати їх дії. Це важливо, оскільки допомагає зрозуміти, як система приймає рішення та як можна покращити її роботу. Такий підхід допомагає забезпечити прозорість та від\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Завдання 3: Використання агента для автоматизації процесів\n",
        "Створіть агента, який допоможе автоматично шукати інформацію про останні наукові публікації в різних галузях. Наприклад, агент має знайти 5 останніх публікацій на тему штучного інтелекту.\n",
        "\n",
        "**Кроки:**\n",
        "1. Налаштуйте агента типу ReAct в LangChain для виконання автоматичних запитів.\n",
        "2. Створіть промпт, який спрямовує агента шукати інформацію в інтернеті або в базах даних наукових публікацій.\n",
        "3. Агент повинен видати список публікацій, кожна з яких містить назву, авторів і короткий опис.\n",
        "\n",
        "Для взаємодії з пошуком там необхідно створити `Tool`. В лекції ми використовували `serpapi`. Можна продовжити користуватись ним, або обрати інше АРІ для пошуку (вони в тому числі є безкоштовні). Перелік різних АРІ, доступних в langchain, і орієнтир по вартості запитів можна знайти в окремому документі [тут](https://hannapylieva.notion.site/API-12994835849480a69b2adf2b8441cbb3?pvs=4).\n",
        "\n",
        "Лишаю також нижче приклад використання одного з безкоштовних пошукових АРІ - DuckDuckGo (не потребує створення токена!)  - можливо він вам сподобається :)\n"
      ],
      "metadata": {
        "id": "m9UsL2gXSe-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community duckduckgo_search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzj4PHP9XwH-",
        "outputId": "fcecf432-565d-48ed-8cc3-609e93ef4e2a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/3.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "search.invoke(\"Obama's first name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "p56AZ_SnXvTs",
        "outputId": "fcee82cc-03d7-4402-a243-0033596a9ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"2 of 2. Barack Obama: timeline Key events in the life of Barack Obama. Barack Obama (born August 4, 1961, Honolulu, Hawaii, U.S.) is the 44th president of the United States (2009-17) and the first African American to hold the office. Before winning the presidency, Obama represented Illinois in the U.S. Senate (2005-08). Since the office was established in 1789, 45 men have served in 46 presidencies. The first president, George Washington, won a unanimous vote of the Electoral College. [4] Grover Cleveland served two non-consecutive terms and is therefore counted as the 22nd and 24th president of the United States, giving rise to the discrepancy between the ... Here is a list of the presidents and vice presidents of the United States along with their parties and dates in office. ... Chester A Arthur: Twenty-First President of the United States. 10 Interesting Facts About James Buchanan. Martin Van Buren - Eighth President of the United States. Quotes From Harry S. Truman. Table of Contents As the head of the government of the United States, the president is arguably the most powerful government official in the world. The president is elected to a four-year term via an electoral college system. Since the Twenty-second Amendment was adopted in 1951, the American presidency has been limited to a maximum of two terms.. Click on a president below to learn more about ... Most common names of U.S. presidents 1789-2021. Published by. Aaron O'Neill, Aug 9, 2024. The most common first name for a U.S. president is James, followed by John and then William. Six U.S ...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# Initialization requested by DuckDuckGo\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Performing a search for publications on the topic of \"artificial intelligence\"\n",
        "query = \"latest scientific publications on artificial intelligence\"\n",
        "results = search.invoke(query)\n",
        "\n",
        "#print(type(results))  # data type\n",
        "#print(results)\n",
        "\n",
        "# Output the result by lines\n",
        "formatted_results = results.split('. ') # Break the text into sentences\n",
        "\n",
        "# Display each sentence separately\n",
        "for sentence in formatted_results:\n",
        "    print(sentence.strip() + \".\\n\")"
      ],
      "metadata": {
        "id": "60jZEitmcCiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ef7fa3-eb00-404f-e303-bc72e2530b41"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give to arXiv this week to help keep science open for all.\n",
            "\n",
            "Donate! ...\n",
            "\n",
            "First Workshop on Explainable Artificial Intelligence for the Medical Domain, European Conference on Artificial Intelligence (ECAI) - 2024, Santiago de Compostela, ...\n",
            "\n",
            "Accepted for publication at EMNLP 2024 Main Conference Subjects: Artificial Intelligence ...\n",
            "\n",
            "Artificial Intelligence (AI) is transforming systematic reviews (SRs) in health research by automating processes such as study screening, data extraction, and quality assessment.\n",
            "\n",
            "This perspective highlights recent advancements in AI tools that enhance efficiency and accuracy in SRs.\n",
            "\n",
            "It discusses the benefits, challenges, and future directions of AI integration, emphasising the need for human ...\n",
            "\n",
            "Abstract.\n",
            "\n",
            "Artificial intelligence (AI) promises to transform medicine, but the geographic concentration of AI expertize may hinder its equitable application.\n",
            "\n",
            "We analyze 397,967 AI life science ...\n",
            "\n",
            "The proliferation of artificial intelligence tools in scientific research risks creating illusions of understanding, where&nbsp;scientists believe they understand more about the world than they ...\n",
            "\n",
            "Annual scholarly publications on artificial intelligence.\n",
            "\n",
            "English- and Chinese-language scholarly publications related to the development and application of AI.\n",
            "\n",
            "This includes journal articles, conference papers, repository publications (such as arXiv), books, and theses.\n",
            "\n",
            "Center for Security and Emerging Technology (2024) - processed by Our ....\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Використала альтернативний спосіб, тому що хотілось би мати список автор, рік публікаціїї, лінк. І я знаю, шо є API, спеціально розроблений для пошуку наукових публікацій, наприклад, Semantic Scholar API."
      ],
      "metadata": {
        "id": "D5y8c6zoQtSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Function for performing a search for publications\n",
        "def search_publications(query, limit=5):\n",
        "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"fields\": \"title,authors,year,url\",\n",
        "        \"limit\": limit\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"data\", [])\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code)\n",
        "        return []\n",
        "\n",
        "# Search publications on the topic \"artificial intelligence\"\n",
        "query = \"artificial intelligence\"\n",
        "publications = search_publications(query)\n",
        "\n",
        "# Output results: Title, authors, year and link\n",
        "for pub in publications:\n",
        "    title = pub.get('title', 'No title')\n",
        "    authors = ', '.join([author['name'] for author in pub.get('authors', [])])\n",
        "    year = pub.get('year', 'No year')\n",
        "    url = pub.get('url', 'No URL')\n",
        "    print(f\"Title: {title}\\nAuthors: {authors}\\nYear: {year}\\nURL: {url}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxMKSntGQb_U",
        "outputId": "0e24b7b7-7e90-4174-c2d4-d0b29e39952e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI\n",
            "Authors: Alejandro Barredo Arrieta, Natalia Díaz Rodríguez, J. Ser, Adrien Bennetot, S. Tabik, A. Barbado, S. García, S. Gil-Lopez, D. Molina, Richard Benjamins, Raja Chatila, Francisco Herrera\n",
            "Year: 2019\n",
            "URL: https://www.semanticscholar.org/paper/530a059cb48477ad1e3d4f8f4b153274c8997332\n",
            "\n",
            "Title: Sparks of Artificial General Intelligence: Early experiments with GPT-4\n",
            "Authors: Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, J. Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Y. Lee, Yuan-Fang Li, Scott M. Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, Yi Zhang\n",
            "Year: 2023\n",
            "URL: https://www.semanticscholar.org/paper/8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c\n",
            "\n",
            "Title: High-performance medicine: the convergence of human and artificial intelligence\n",
            "Authors: E. Topol\n",
            "Year: 2019\n",
            "URL: https://www.semanticscholar.org/paper/f134abeaf9bfd41f29b97aec675ec31895bf541d\n",
            "\n",
            "Title: Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)\n",
            "Authors: Amina Adadi, M. Berrada\n",
            "Year: 2018\n",
            "URL: https://www.semanticscholar.org/paper/21dff47a4142445f83016da0819ffe6dd2947f66\n",
            "\n",
            "Title: Explainable Artificial Intelligence (XAI)\n",
            "Authors: Ranu Sewada, Ashwani Jangid, Piyush Kumar, Neha Mishra\n",
            "Year: 2023\n",
            "URL: https://www.semanticscholar.org/paper/e1d2f2a717aa03280126f87c8e5fad695f52bf7c\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Завдання 4: Створення агента-помічника для вирішення бізнес-задач\n",
        "\n",
        "Створіть агента, який допомагає вирішувати задачі бізнес-аналітики. Агент має допомогти користувачу створити прогноз по продажам на наступний рік враховуючи рівень інфляції і погодні умови. Агент має вміти використовувати Python і ходити в інтернет аби отримати актуальні дані.\n",
        "\n",
        "**Кроки:**\n",
        "1. Налаштуйте агента, який працюватиме з аналітичними даними, заданими текстом. Користувач пише\n",
        "\n",
        "```\n",
        "Ми експортуємо апельсини з Бразилії. В 2021 експортували 200т, в 2022 - 190т, в 2023 - 210т, в 2024 який ще не закінчився - 220т. Зроби оцінку скільки ми зможемо експортувати апельсинів в 2025 враховуючи погодні умови в Бразилії і попит на апельсини в світі виходячи з економічної ситуації.\n",
        "```\n",
        "\n",
        "2. Створіть запит до агента, що містить чітке завдання – видати результат бізнес аналізу або написати, що він не може цього зробити і запит користувача (просто може бути все одним повідомлленням).\n",
        "\n",
        "3. Запустіть агента і проаналізуйте результати. Що можна покращити?\n"
      ],
      "metadata": {
        "id": "IOqujC6qY_NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract keys from file\n",
        "weather_api_key = creds['weather_api_key']\n",
        "news_api_key = creds['news_api_key']"
      ],
      "metadata": {
        "id": "z1k0C2LsWadg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weather data\n",
        "city = \"Sao Paulo\"\n",
        "url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={weather_api_key}&units=metric\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Checking the status of the request\n",
        "if response.status_code == 200:\n",
        "    weather_data = response.json()\n",
        "    print(weather_data)  # Output for debugging\n",
        "\n",
        "    # Extracting data\n",
        "    temperature = weather_data.get('main', {}).get('temp', 'Нет данных')\n",
        "    precipitation = weather_data.get('rain', {}).get('1h', 0)\n",
        "    weather_description = weather_data.get('weather', [{}])[0].get('description', 'Нет данных')\n",
        "\n",
        "    # Output weather data\n",
        "    weather_info = f\"Температура в {city}: {temperature}°C, рівень опадів: {precipitation} мм, стан: {weather_description}.\"\n",
        "    print(weather_info)\n",
        "else:\n",
        "    print(f\"Request error: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY45D5DmXL5O",
        "outputId": "6ac2d583-be73-42e5-d6f0-983fb016457a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'coord': {'lon': -46.6361, 'lat': -23.5475}, 'weather': [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01d'}], 'base': 'stations', 'main': {'temp': 24.1, 'feels_like': 24.63, 'temp_min': 23.75, 'temp_max': 24.94, 'pressure': 1013, 'humidity': 79, 'sea_level': 1013, 'grnd_level': 925}, 'visibility': 10000, 'wind': {'speed': 4.63, 'deg': 330}, 'clouds': {'all': 0}, 'dt': 1729939071, 'sys': {'type': 1, 'id': 8394, 'country': 'BR', 'sunrise': 1729931052, 'sunset': 1729977389}, 'timezone': -10800, 'id': 3448439, 'name': 'São Paulo', 'cod': 200}\n",
            "Температура в Sao Paulo: 24.1°C, рівень опадів: 0 мм, стан: clear sky.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the key to find news about demand for oranges\n",
        "query = \"demand for oranges\"\n",
        "url_news = f\"https://newsapi.org/v2/everything?q={query}&apiKey={news_api_key}\"\n",
        "\n",
        "# Execute the request\n",
        "response_news = requests.get(url_news)\n",
        "news_data = response_news.json()\n",
        "\n",
        "# Extracting news headlines\n",
        "if news_data['status'] == 'ok':\n",
        "    top_news = news_data['articles'][:3]  # We take 3 top news\n",
        "    economy_info = \" \".join([article['title'] for article in top_news])\n",
        "else:\n",
        "    economy_info = \"Unable to obtain demand data for oranges.\"\n",
        "\n",
        "print(economy_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ci8UVMaMEr",
        "outputId": "496d1e9e-68c2-4796-a509-4bfa3e8c1d2d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What Zoya Sees The very specific reasons certain prices are spiking: (Hint: It’s not Biden) Our Comprehensive, Inconclusive Diversity Database\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for forecast\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"weather\", \"economy\"],\n",
        "    template=\"\"\"\n",
        "    Ми експортуємо апельсини з Бразилії. В 2021 експортували 200т, в 2022 - 190т, в 2023 - 210т, в 2024 який ще не закінчився - 220т.\n",
        "    Враховуючи погодні умови в Бразилії: {weather}, та світовий попит на апельсини з урахуванням економічної ситуації: {economy},\n",
        "    Зробіть прогноз, скільки тонн апельсинів ми зможемо експортувати у 2025 році.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Form the final prompt\n",
        "final_prompt = prompt_template.format(\n",
        "    weather=weather_info,\n",
        "    economy=economy_info\n",
        ")\n",
        "\n",
        "# Response from the model\n",
        "response = llm(final_prompt)\n",
        "\n",
        "# Result\n",
        "print(f\"Прогноз експорту на 2025 год:\\n{response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cYlglQmbRGC",
        "outputId": "afdf5a1b-b566-4e38-bcef-3b43622757e5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Прогноз експорту на 2025 год:\n",
            "\n",
            "За умови, що погодні умови в Бразилії залишаться стабільними, а світовий попит на апельсини збережеться на тому ж рівні, ми можемо прогнозувати, що у 2025 році ми зможемо експортувати близько 230-240 тонн апельсинів з Бразилії. Однак, слід враховувати, що економічна ситуація може змінитися, що може вплинути на попит на апельсини та їх ціну. Тому, цей прогноз є лише орієнтовним і може змінитися в залежності ві\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Варіанти покращення:\n",
        "1. Зараз в приклады використано поточні погодні дані. Можливо, варто спробувати одержати довгострокові прогнози погоди, щоб краще враховувати майбутні погодні умови в Бразилії, які можуть вплинути на врожай апельсинів. API OpenWeather надає прогноз на кілька днів уперед, що дозволить врахувати зміни погоди, які можуть вплинути на врожай.\n",
        "\n",
        "2. Замість використання останніх новин про попит на апельсини, можна отримати більш детальні дані про економічні прогнози попиту, використовуючи інші API, а не тільки новини.Можно було б аналізувати глобальні тенденції у виробництві фруктів, щоб передбачити зміни у попиті. *за умов наявності історичних даних.\n",
        "\n",
        "3. Взагалі це задача ML. І для прогнозування експорту в 2025 році можно було б навчити модель на історичних даних про експорт, погоду та попи та отримати більш точний прогноз.\n",
        "\n",
        "4. Додати візуалізацію прогнозів, щоб краще розуміти динамік (matplotlib або plotly, для створення графіків, що показують зміну попиту та погодних умов)."
      ],
      "metadata": {
        "id": "iYTq4uJTdXoX"
      }
    }
  ]
}