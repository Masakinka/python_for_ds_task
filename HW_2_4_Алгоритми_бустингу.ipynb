{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masakinka/python_for_ds_task/blob/main/HW_2_4_%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B8_%D0%B1%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3%D1%83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В цьому домашньому завданні ми знову працюємо з даними з нашого змагання [\"Bank Customer Churn Prediction (DLU Course)\"](https://www.kaggle.com/t/7c080c5d8ec64364a93cf4e8f880b6a0).\n",
        "\n",
        "Тут ми побудуємо рішення задачі класифікації з використанням алгоритмів бустингу: XGBoost та LightGBM, а також використаємо бібліотеку HyperOpt для оптимізації гіперпараметрів."
      ],
      "metadata": {
        "id": "fDefDHQt8LXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Зчитайте дані `train.csv` в змінну `raw_df` та скористайтесь наведеним кодом нижче аби розділити дані на трнувальні та валідаційні і розділити дані на ознаки з матириці Х та цільову змінну. Назви змінних `train_inputs, train_targets, train_inputs, train_targets` можна змінити на ті, які Вам зручно.\n",
        "\n",
        "  Наведений скрипт - частина отриманого мною скрипта для обробки даних. Ми тут не викнуємо масштабування та обробку категоріальних змінних, бо хочемо це делегувати алгоритмам, які будемо використовувати. Якщо щось не розумієте в наведених скриптах, рекомендую розібратись: навичка читати код - важлива складова роботи в машинному навчанні."
      ],
      "metadata": {
        "id": "LhivzW9W8-Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Підключення Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsoPoilljiYh",
        "outputId": "83677056-5b95-4e2b-ac3a-c4b8937b9a7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ],
      "metadata": {
        "id": "-YzWuyj0n5rc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperopt --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yrp3iD10vfgF",
        "outputId": "96836470-6730-43b1-93a3-e353894f1253"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from typing import Tuple, Dict, Any\n",
        "\n",
        "import xgboost as xgb\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n"
      ],
      "metadata": {
        "id": "X2tdn0Nyop5F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max.rows',130)\n",
        "pd.set_option('display.max.columns',130)\n",
        "pd.set_option('float_format', '{:.2f}'.format)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.expand_frame_repr', False)"
      ],
      "metadata": {
        "id": "snYr19m2qIl5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантаження даних з Kaggle\n",
        "dataset_url = 'https://www.kaggle.com/competitions/bank-customer-churn-prediction-dlu/'\n",
        "od.download(dataset_url)\n",
        "data_dir = './bank-customer-churn-prediction-dlu'\n",
        "raw_df = pd.read_csv('./bank-customer-churn-prediction-dlu/train.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlPfNXrqoBZ0",
        "outputId": "922c2676-734c-4329-e623-7184c26a4cdd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: viktoriiabortnikova\n",
            "Your Kaggle Key: ··········\n",
            "Downloading bank-customer-churn-prediction-dlu.zip to ./bank-customer-churn-prediction-dlu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 637k/637k [00:00<00:00, 46.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting archive ./bank-customer-churn-prediction-dlu/bank-customer-churn-prediction-dlu.zip to ./bank-customer-churn-prediction-dlu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_val(df: pd.DataFrame, target_col: str, test_size: float = 0.2, random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split the dataframe into training and validation sets.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The raw dataframe.\n",
        "        target_col (str): The target column for stratification.\n",
        "        test_size (float): The proportion of the dataset to include in the validation split.\n",
        "        random_state (int): Random state for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame]: Training and validation dataframes.\n",
        "    \"\"\"\n",
        "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[target_col])\n",
        "    return train_df, val_df\n",
        "\n",
        "\n",
        "def separate_inputs_targets(df: pd.DataFrame, input_cols: list, target_col: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    \"\"\"\n",
        "    Separate inputs and targets from the dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataframe.\n",
        "        input_cols (list): List of input columns.\n",
        "        target_col (str): Target column.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.Series]: DataFrame of inputs and Series of targets.\n",
        "    \"\"\"\n",
        "    inputs = df[input_cols].copy()\n",
        "    targets = df[target_col].copy()\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "cKE8RTPf6CRD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = 'Exited'\n",
        "input_columns = raw_df.columns.difference([target_column]).tolist()\n",
        "\n",
        "train_df, val_df = split_train_val(raw_df, target_col=target_column)\n",
        "train_inputs, train_targets = separate_inputs_targets(train_df, input_cols=input_columns, target_col=target_column)\n",
        "val_inputs, val_targets = separate_inputs_targets(val_df, input_cols=input_columns, target_col=target_column)\n",
        "\n",
        "# Виведення результатів для перевірки\n",
        "print(\"Train inputs:\")\n",
        "print(train_inputs.head())\n",
        "print(\"Train targets:\")\n",
        "print(train_targets.head())\n",
        "print(\"Validation inputs:\")\n",
        "print(val_inputs.head())\n",
        "print(\"Validation targets:\")\n",
        "print(val_targets.head())"
      ],
      "metadata": {
        "id": "-bHdMJVB4xQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7930de5d-7175-46b1-8d96-9d7cf6f77be5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train inputs:\n",
            "        Age   Balance  CreditScore  CustomerId  EstimatedSalary  Gender Geography  HasCrCard  IsActiveMember  NumOfProducts    Surname  Tenure     id\n",
            "7180  30.00 131394.56       682.00 15652218.00        143952.24    Male    France       1.00            1.00           1.00       Mays    1.00   7180\n",
            "10393 39.00 178058.06       684.00 15592937.00        145518.31  Female    France       1.00            0.00           1.00     Ch'eng    2.00  10393\n",
            "80    35.00 116320.68       705.00 15774586.00        174431.01    Male   Germany       1.00            0.00           2.00      Ch'in    6.00     80\n",
            "3365  58.00      0.00       669.00 15780572.00         51565.98    Male     Spain       0.00            1.00           2.00         K?    0.00   3365\n",
            "12236 21.00      0.00       707.00 15642099.00        148564.76    Male    France       1.00            1.00           2.00  Trevisani    3.00  12236\n",
            "Train targets:\n",
            "7180    0.00\n",
            "10393   0.00\n",
            "80      0.00\n",
            "3365    0.00\n",
            "12236   0.00\n",
            "Name: Exited, dtype: float64\n",
            "Validation inputs:\n",
            "       Age   Balance  CreditScore  CustomerId  EstimatedSalary  Gender Geography  HasCrCard  IsActiveMember  NumOfProducts   Surname  Tenure    id\n",
            "6490 46.00 115764.32       714.00 15794345.00         72945.32    Male   Germany       1.00            1.00           4.00   Pirozzi    1.00  6490\n",
            "3646 41.00      0.00       593.00 15617348.00         38196.24    Male    France       1.00            1.00           2.00   Ritchie    5.00  3646\n",
            "5306 38.00      0.00       731.00 15787907.00        116971.05  Female    France       0.00            1.00           2.00     Hs?eh    2.00  5306\n",
            "652  43.00 155739.76       673.00 15803378.00        111622.76  Female    France       0.00            1.00           1.00      Onio    4.00   652\n",
            "2627 30.00      0.00       678.00 15772423.00        143681.85  Female     Spain       1.00            0.00           2.00  Genovesi    4.00  2627\n",
            "Validation targets:\n",
            "6490   1.00\n",
            "3646   0.00\n",
            "5306   0.00\n",
            "652    0.00\n",
            "2627   0.00\n",
            "Name: Exited, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. В тренувальному та валідаційному наборі перетворіть категоріальні ознаки на тип `category`. Можна це зробити двома способами:\n",
        " 1. `df[col_name].astype('category')`, як було продемонстровано в лекції\n",
        " 2. використовуючи метод `pd.Categorical(df[col_name])`"
      ],
      "metadata": {
        "id": "cq0JU7MqHgp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначення категоріальних колонок\n",
        "categorical_columns = raw_df.select_dtypes(include=['object']).columns.tolist()\n",
        "categorical_columns"
      ],
      "metadata": {
        "id": "UPmqo-Mr4yUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aec8921-9c6e-4ef4-8fa1-93b47ca14752"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Surname', 'Geography', 'Gender']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Перетворення категоріальних ознак на тип category\n",
        "#for col in categorical_columns:\n",
        "#    train_inputs[col] = train_inputs[col].astype('category')\n",
        "#    val_inputs[col] = val_inputs[col].astype('category')\n",
        "\n",
        "# Альтернативний спосіб використання pd.Categorical\n",
        "for col in categorical_columns:\n",
        "    train_inputs[col] = pd.Categorical(train_inputs[col])\n",
        "    val_inputs[col] = pd.Categorical(val_inputs[col])\n",
        "\n",
        "# Виведення результатів для перевірки\n",
        "print(\"Train inputs:\")\n",
        "print(train_inputs.dtypes)\n",
        "print(\"Validation inputs:\")\n",
        "print(val_inputs.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At7LjZceteQg",
        "outputId": "e39fe6f4-2442-446a-830d-0a4c1bd486de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train inputs:\n",
            "Age                 float64\n",
            "Balance             float64\n",
            "CreditScore         float64\n",
            "CustomerId          float64\n",
            "EstimatedSalary     float64\n",
            "Gender             category\n",
            "Geography          category\n",
            "HasCrCard           float64\n",
            "IsActiveMember      float64\n",
            "NumOfProducts       float64\n",
            "Surname            category\n",
            "Tenure              float64\n",
            "id                    int64\n",
            "dtype: object\n",
            "Validation inputs:\n",
            "Age                 float64\n",
            "Balance             float64\n",
            "CreditScore         float64\n",
            "CustomerId          float64\n",
            "EstimatedSalary     float64\n",
            "Gender             category\n",
            "Geography          category\n",
            "HasCrCard           float64\n",
            "IsActiveMember      float64\n",
            "NumOfProducts       float64\n",
            "Surname            category\n",
            "Tenure              float64\n",
            "id                    int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Навчіть на отриманих даних модель `XGBoostClassifier`. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
        "\n",
        "  Опис всіх конфігураційних параметрів XGBoostClassifier - тут https://xgboost.readthedocs.io/en/stable/parameter.html#global-config\n",
        "\n",
        "  **Важливо:** зробіть такі налаштування `XGBoostClassifier` аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
        "\n",
        "  Можна також, якщо працюєте в Google Colab, увімкнути можливість використання GPU (`Runtime -> Change runtime type -> T4 GPU`) і встановити параметр `device='cuda'` в `XGBoostClassifier` для пришвидшення тренування бустинг моделі.\n",
        "  \n",
        "  Після тренування моделі\n",
        "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
        "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
        "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням DecisionTrees раніше. Чи вийшло покращити якість?"
      ],
      "metadata": {
        "id": "_LxWkv4o-wMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Тренування моделі XGBClassifier\n",
        "xgb_clf = XGBClassifier(\n",
        "    use_label_encoder=False,  # щоб уникнути попереджень, якщо використовуєте нові версії XGBoost\n",
        "    missing=np.nan,  # явне вказування пропущених значень\n",
        "    enable_categorical=True,  # Обробка категоріальних колонок\n",
        "    random_state=42,  # Випадковий стан для відтворюваності результатів\n",
        "    device='cuda',\n",
        "    max_depth=3,\n",
        "    n_estimators=10\n",
        ")\n",
        "\n",
        "xgb_clf.fit(train_inputs, train_targets)"
      ],
      "metadata": {
        "id": "_5rDqdDP41hb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "9b7e77cb-eede-4ad1-ace5-78aef3576a6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [15:49:22] WARNING: /workspace/src/context.cc:44: No visible GPU is found, setting device to CPU.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
              "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=10, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=10, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=10, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Прогнозування на тренувальному та валідаційному наборах\n",
        "train_preds = xgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds = xgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "# Вимірювання точності з допомогою AUROC\n",
        "train_auc = roc_auc_score(train_targets, train_preds)\n",
        "val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "print(f\"Train AUROC: {train_auc}\")\n",
        "print(f\"Validation AUROC: {val_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQvv9n1NBDGW",
        "outputId": "162240ff-4d7d-42fe-a936-8ac39c61ad2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train AUROC: 0.9421334105891545\n",
            "Validation AUROC: 0.9251563893271144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = xgb_clf.predict(train_inputs)\n",
        "val_pred = xgb_clf.predict(val_inputs)\n",
        "\n",
        "print(classification_report(train_targets, train_pred, digits=4))\n",
        "print(classification_report(val_targets, val_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaJszTIkJpO4",
        "outputId": "8097f499-3735-4f08-cbab-a539ff447e8b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9162    0.9684    0.9416      9558\n",
            "         1.0     0.8408    0.6532    0.7352      2442\n",
            "\n",
            "    accuracy                         0.9042     12000\n",
            "   macro avg     0.8785    0.8108    0.8384     12000\n",
            "weighted avg     0.9008    0.9042    0.8996     12000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9047    0.9653    0.9340      2390\n",
            "         1.0     0.8156    0.6016    0.6925       610\n",
            "\n",
            "    accuracy                         0.8913      3000\n",
            "   macro avg     0.8601    0.7835    0.8132      3000\n",
            "weighted avg     0.8866    0.8913    0.8849      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для класу 1 (меншості) на тренувальному наборі модель досягає значення 0.6532, тоді як на валідаційному лише 0.6016.Зниження F1-score на валідаційній вибірці в порівнянні з тренувальною також вказує на те, що модель може бути перенавчена на тренувальних даних. Існують ознаки переобучення, але вони незначні. Модель демонструє кращі результати на тренувальній вибірці\n",
        "\n"
      ],
      "metadata": {
        "id": "_yFJWSywLASC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновки**:\n",
        "Результати AUROC на тренувальній та валідаційній вибірках досить близькі (0.942 проти 0.925), що свідчить про добре збалансовану модель.\n",
        "Враховуючи високі значення AUROC на обох наборах, можна сказати, що модель не страждає від High Bias (низька точність) або High Variance (перенавчання).\n",
        "Модель XGBClassifier є більш точною та збалансованою, ніж Decision Trees, але покращення не є радикальним."
      ],
      "metadata": {
        "id": "18oXWFUTHxup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `XGBoostClassifier` з лекції знайдіть оптимальні значення гіперпараметрів `XGBoostClassifier` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **20**.\n",
        "\n",
        "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. В ній ми маємо задати loss - це може будь-яка метрика, але бажано використовувтаи ту, яка цільова в вашій задачі. Чим менший лосс - тим ліпша модель на думку hyperopt. Тож, тут нам треба задати loss - негативне значення AUROC. В лекції ми натомість використовували Accuracy.\n",
        "\n",
        "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
        "    - виведіть найкращі значення гіперпараметрів\n",
        "    - створіть в окремій зміній `final_clf` модель `XGBoostClassifier` з найкращими гіперпараметрами\n",
        "    - навчіть модель `final_clf`\n",
        "    - оцініть якість моделі `final_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
        "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (2) цього завдання?"
      ],
      "metadata": {
        "id": "U4hm5qYs_f7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(params):\n",
        "    clf = xgb.XGBClassifier(\n",
        "        n_estimators=int(params['n_estimators']),\n",
        "        learning_rate=params['learning_rate'],\n",
        "        max_depth=int(params['max_depth']),\n",
        "        min_child_weight=params['min_child_weight'],  # Мінімальна сума ваг всіх вибірок, необхідна в кінцевому вузлі\n",
        "        subsample=params['subsample'],  # Частка вибірок, що використовуються для побудови кожного дерева\n",
        "        colsample_bytree=params['colsample_bytree'],  # Частка ознак, що використовуються при побудові кожного дерева\n",
        "        gamma=params['gamma'],  # Мінімальне зменшення втрат, необхідне для виконання поділу\n",
        "        reg_alpha=params['reg_alpha'],  # Параметр регуляризації L1 (Lasso)\n",
        "        reg_lambda=params['reg_lambda'],  # Параметр регуляризації L2 (Ridge)\n",
        "        enable_categorical=True,\n",
        "        use_label_encoder=False,\n",
        "        missing=np.nan,\n",
        "      #  device='cuda',\n",
        "        early_stopping_rounds=10\n",
        "    )\n",
        "    clf.fit(\n",
        "        train_inputs,\n",
        "        train_targets,\n",
        "        eval_set=[(val_inputs, val_targets)],\n",
        "        eval_metric=\"auc\",\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    pred = clf.predict_proba(val_inputs)[:, 1]\n",
        "    auc = roc_auc_score(val_targets, pred)\n",
        "\n",
        "    return {'loss': -auc, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "WhR1g9B4433r"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Простір гіперпараметрів\n",
        "space = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 500, 25),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
        "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
        "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
        "    'gamma': hp.uniform('gamma', 0, 0.5),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0, 1)\n",
        "}\n",
        "\n",
        "# Оптимізація\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
        "\n",
        "# Перетворення значень гіперпараметрів у кінцеві типи\n",
        "best['n_estimators'] = int(best['n_estimators'])\n",
        "best['max_depth'] = int(best['max_depth'])\n",
        "best['min_child_weight'] = int(best['min_child_weight'])\n",
        "\n",
        "print(\"Найкращі гіперпараметри: \", best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OAqE0NaSeLHQ",
        "outputId": "328bb559-a640-443b-b5c1-36bb24577e85"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5%|▌         | 1/20 [00:01<00:25,  1.35s/trial, best loss: -0.9332447355785719]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|█         | 2/20 [00:02<00:22,  1.25s/trial, best loss: -0.9332447355785719]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15%|█▌        | 3/20 [00:02<00:13,  1.27trial/s, best loss: -0.9332447355785719]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 25%|██▌       | 5/20 [00:03<00:06,  2.23trial/s, best loss: -0.9341072775910557]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 35%|███▌      | 7/20 [00:03<00:04,  3.12trial/s, best loss: -0.9366544344605253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|████      | 8/20 [00:04<00:03,  3.18trial/s, best loss: -0.9366544344605253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45%|████▌     | 9/20 [00:04<00:03,  3.32trial/s, best loss: -0.9366544344605253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|█████     | 10/20 [00:04<00:02,  3.66trial/s, best loss: -0.9366544344605253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:04<00:02,  3.83trial/s, best loss: -0.9366544344605253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 65%|██████▌   | 13/20 [00:05<00:01,  3.61trial/s, best loss: -0.9366544344605253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70%|███████   | 14/20 [00:06<00:04,  1.48trial/s, best loss: -0.9366544344605253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:08<00:04,  1.09trial/s, best loss: -0.9369092530351875]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 85%|████████▌ | 17/20 [00:09<00:02,  1.39trial/s, best loss: -0.9369092530351875]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90%|█████████ | 18/20 [00:09<00:01,  1.76trial/s, best loss: -0.9369092530351875]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:10<00:00,  2.07trial/s, best loss: -0.9369092530351875]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [00:10<00:00,  1.90trial/s, best loss: -0.9369092530351875]\n",
            "Найкращі гіперпараметри:  {'colsample_bytree': 0.6762631141197977, 'gamma': 0.4680434822912656, 'learning_rate': 0.11645950195845559, 'max_depth': 6, 'min_child_weight': 7, 'n_estimators': 125, 'reg_alpha': 0.051228249232658674, 'reg_lambda': 0.3837623843846182, 'subsample': 0.6049314496241731}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbM4E0Pdtd5P",
        "outputId": "04706643-ae9b-4b8a-c95f-99dfcec2eb27"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.6762631141197977,\n",
              " 'gamma': 0.4680434822912656,\n",
              " 'learning_rate': 0.11645950195845559,\n",
              " 'max_depth': 6,\n",
              " 'min_child_weight': 7,\n",
              " 'n_estimators': 125,\n",
              " 'reg_alpha': 0.051228249232658674,\n",
              " 'reg_lambda': 0.3837623843846182,\n",
              " 'subsample': 0.6049314496241731}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Навчання фінальної моделі з найкращими гіперпараметрами\n",
        "final_clf = xgb.XGBClassifier(\n",
        "    n_estimators=best['n_estimators'],\n",
        "    learning_rate=best['learning_rate'],\n",
        "    max_depth=best['max_depth'],\n",
        "    min_child_weight=best['min_child_weight'],\n",
        "    subsample=best['subsample'],\n",
        "    colsample_bytree=best['colsample_bytree'],\n",
        "    gamma=best['gamma'],\n",
        "    reg_alpha=best['reg_alpha'],\n",
        "    reg_lambda=best['reg_lambda'],\n",
        "    enable_categorical=True,\n",
        "    use_label_encoder=False,\n",
        "    missing=np.nan,\n",
        "    device='cpu',  # Використовуйте CPU\n",
        "    eval_metric=\"auc\"\n",
        ")\n",
        "\n",
        "final_clf.fit(train_inputs, train_targets)\n",
        "train_preds = final_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds = final_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "train_auc = roc_auc_score(train_targets, train_preds)\n",
        "val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "print(f\"Train AUROC: {train_auc:.4f}\")\n",
        "print(f\"Validation AUROC: {val_auc:.4f}\")\n",
        "\n",
        "# Оцінка моделі з використанням classification_report\n",
        "train_pred = final_clf.predict(train_inputs)\n",
        "val_pred = final_clf.predict(val_inputs)\n",
        "\n",
        "print(classification_report(train_targets, train_pred, digits=4))\n",
        "print(classification_report(val_targets, val_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhnxCSfPtEuP",
        "outputId": "896ba23b-45e4-46ff-ee76-9da82adc769b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train AUROC: 0.9700\n",
            "Validation AUROC: 0.9325\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9433    0.9742    0.9585      9558\n",
            "         1.0     0.8840    0.7707    0.8235      2442\n",
            "\n",
            "    accuracy                         0.9327     12000\n",
            "   macro avg     0.9136    0.8724    0.8910     12000\n",
            "weighted avg     0.9312    0.9327    0.9310     12000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9188    0.9519    0.9351      2390\n",
            "         1.0     0.7805    0.6705    0.7213       610\n",
            "\n",
            "    accuracy                         0.8947      3000\n",
            "   macro avg     0.8497    0.8112    0.8282      3000\n",
            "weighted avg     0.8907    0.8947    0.8916      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель final_clf з оптимізованими гіперпараметрами показала кращу якість порівняно з попередньою моделлю.\n",
        "- Покращення AUROC на тренувальній вибірці: 0.9700 проти 0.9421;\n",
        "- Покращення AUROC на валідаційній вибірці: 0.9325 проти 0.9251\n",
        "\n",
        "Таким чином, оптимізація гіперпараметрів дозволила покращити якість моделі, особливо на тренувальній вибірці, при цьому модель не демонструє значного переобучення, оскільки покращення AUROC на валідаційній вибірці також наявне."
      ],
      "metadata": {
        "id": "7uU7RpPXuubs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Навчіть на наших даних модель LightGBM. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
        "\n",
        "  Опис всіх конфігураційних параметрів LightGBM - тут https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "\n",
        "  **Важливо:** зробіть такі налаштування LightGBM аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
        "\n",
        "  Аби передати категоріальні колонки в LightGBM - необхідно виявити їх індекси і передати в параметрі `cat_feature=cat_feature_indexes`\n",
        "\n",
        "  Після тренування моделі\n",
        "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
        "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
        "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням XGBoostClassifier раніше. Чи вийшло покращити якість?"
      ],
      "metadata": {
        "id": "Vg77SVWrBBmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "sudo apt-get update\n",
        "sudo apt-get install -y build-essential cmake git wget unzip\n",
        "sudo apt-get install -y libboost-dev libboost-system-dev libboost-filesystem-dev\n",
        "sudo apt-get install -y libboost-iostreams-dev libboost-program-options-dev libboost-regex-dev\n",
        "sudo apt-get install -y libboost-thread-dev libboost-chrono-dev libboost-date-time-dev\n",
        "sudo apt-get install -y libboost-atomic-dev libboost-serialization-dev\n",
        "sudo apt-get install -y python3-pip"
      ],
      "metadata": {
        "id": "C-9aZn4d45No",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "edbf8045-2e6b-405d-f006-a87a8a4399ba"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,073 kB]\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,128 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,721 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,204 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,550 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,418 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,338 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,795 kB]\n",
            "Fetched 23.5 MB in 4s (6,569 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-dev set to manually installed.\n",
            "libboost-filesystem-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-filesystem-dev set to manually installed.\n",
            "libboost-system-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-system-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-program-options-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-program-options-dev set to manually installed.\n",
            "libboost-regex-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-regex-dev set to manually installed.\n",
            "libboost-iostreams-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-iostreams-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-thread-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-thread-dev set to manually installed.\n",
            "libboost-chrono-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-chrono-dev set to manually installed.\n",
            "libboost-date-time-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-date-time-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-atomic-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-atomic-dev set to manually installed.\n",
            "libboost-serialization-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-serialization-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,967 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.4 [1,305 kB]\n",
            "Fetched 1,677 kB in 0s (5,415 kB/s)\n",
            "Selecting previously unselected package python3-setuptools.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 123589 files and directories currently installed.)\r\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\r\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package python3-wheel.\r\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\r\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package python3-pip.\r\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.4_all.deb ...\r\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\r\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\r\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\r\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\r\n",
            "Processing triggers for man-db (2.10.2-1) ...\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "sudo apt-get install -y ocl-icd-libopencl1 clinfo\n",
        "sudo apt-get install -y nvidia-opencl-dev opencl-headers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Co1gjErTvyNY",
        "outputId": "7cb0e702-8004-49f0-b0c9-cac415838be8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "clinfo is already the newest version (3.0.21.02.21-1).\n",
            "ocl-icd-libopencl1 is already the newest version (2.2.14-3).\n",
            "ocl-icd-libopencl1 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "nvidia-opencl-dev is already the newest version (11.5.1-1ubuntu1).\n",
            "The following NEW packages will be installed:\n",
            "  opencl-headers\n",
            "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 1,754 B of archives.\n",
            "After this operation, 12.3 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 opencl-headers all 3.0~2022.01.04-1 [1,754 B]\n",
            "Fetched 1,754 B in 0s (11.6 kB/s)\n",
            "Selecting previously unselected package opencl-headers.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 124451 files and directories currently installed.)\r\n",
            "Preparing to unpack .../opencl-headers_3.0~2022.01.04-1_all.deb ...\r\n",
            "Unpacking opencl-headers (3.0~2022.01.04-1) ...\r\n",
            "Setting up opencl-headers (3.0~2022.01.04-1) ...\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone --recursive https://github.com/microsoft/LightGBM\n",
        "cd LightGBM\n",
        "mkdir build\n",
        "cd build\n",
        "cmake -DUSE_CUDAP=1 ..\n",
        "make -j4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW5OyMXOwwt3",
        "outputId": "eaf4e9a4-08ba-4fcf-fa6e-e9917c79a57f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is interrupted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "print(lgb.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLcKw28pxSCm",
        "outputId": "fd54f5e9-9202-4f41-d55b-65a905392b4a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_feature_indexes = [train_inputs.columns.get_loc(col) for col in categorical_columns]"
      ],
      "metadata": {
        "id": "PFbVzhsrxckf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_clf = lgb.LGBMClassifier(\n",
        "    max_depth=3,\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.1,\n",
        "    cat_feature=cat_feature_indexes,  # для автоматичного розпізнавання категорійних ознак\n",
        "    missing=np.nan,  # явне вказування пропущених значень\n",
        "    # device='cuda'  # використовувати GPU для прискорення обчислень\n",
        ")\n",
        "\n",
        "# Навчання моделі\n",
        "lgb_clf.fit(train_inputs, train_targets, eval_set=[(val_inputs, val_targets)])\n",
        "\n",
        "# Прогнозування та оцінка якості\n",
        "train_preds = lgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds = lgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "train_auc = roc_auc_score(train_targets, train_preds)\n",
        "val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "print(f\"Train AUROC: {train_auc:.4f}\")\n",
        "print(f\"Validation AUROC: {val_auc:.4f}\")\n",
        "\n",
        "# Оцінка моделі з використанням classification_report\n",
        "train_pred = lgb_clf.predict(train_inputs)\n",
        "val_pred = lgb_clf.predict(val_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjx299NZy8Yc",
        "outputId": "c0061b14-ca18-436d-d326-7c3146258990"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set with cat_feature=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1826\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "Train AUROC: 0.9501\n",
            "Validation AUROC: 0.9355\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9241    0.9688    0.9459      9558\n",
            "         1.0     0.8494    0.6884    0.7605      2442\n",
            "\n",
            "    accuracy                         0.9117     12000\n",
            "   macro avg     0.8867    0.8286    0.8532     12000\n",
            "weighted avg     0.9089    0.9117    0.9082     12000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9169    0.9598    0.9379      2390\n",
            "         1.0     0.8072    0.6590    0.7256       610\n",
            "\n",
            "    accuracy                         0.8987      3000\n",
            "   macro avg     0.8620    0.8094    0.8317      3000\n",
            "weighted avg     0.8946    0.8987    0.8947      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель має високі значення AUROC як на тренувальній, так і на валідаційній вибірках (0.9501 та 0.9355 відповідно). Це свідчить про те, що модель добре навчається на тренувальних даних і не має значної упередженості (bias).\n",
        "\n",
        " Різниця між AUROC на тренувальній та валідаційній вибірках незначна (0.9501 проти 0.9355), що свідчить про те, що модель не страждає від сильної варіативності (variance).\n",
        "\n",
        "Загальна оцінка:\n",
        "Модель є хорошою. Значення AUROC більше 0.9 на обох вибірках свідчать про те, що модель добре розрізняє класи.\n",
        "Немає ознак high bias або high variance, бо модель добре збалансована і показує хороші результати як на тренувальній, так і на валідаційній вибірках.\n",
        "А метрики F1-score, precision та recall також свідчать про хорошу якість моделі, хоча recall для класу 1 можна покращити."
      ],
      "metadata": {
        "id": "I9JOLQzL1wC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновок**: Модель LightGBM показує трохи кращий результат на валідаційній вибірці (0.9355) порівняно з XGBoost (0.9325). Однак на тренувальній вибірці LightGBM (0.9501) поступається XGBoost (0.9700).\n",
        "\n",
        "Загальна точність моделі LightGBM на валідаційній вибірці (0.8987) трохи вища за точність XGBoost (0.8947).\n",
        "Precision і Recall для класу 1 в LightGBM нижчі, ніж у XGBoost, що свідчить про те, що модель LightGBM краще підходить для класу 0."
      ],
      "metadata": {
        "id": "WyXqo9t81Cg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `LightGBM` з лекції знайдіть оптимальні значення гіперпараметрів `LightGBM` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **10**.\n",
        "\n",
        "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. І тут ми також ставимо loss - негативне значення AUROC, як і при пошуці гіперпараметрів для XGBoost. До речі, можна спробувати написати код так, аби в objective передавати лише модель і не писати схожий код двічі :)\n",
        "\n",
        "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
        "    - виведіть найкращі значення гіперпараметрів\n",
        "    - створіть в окремій зміній `final_lgb_clf` модель `LightGBM` з найкращими гіперпараметрами\n",
        "    - навчіть модель `final_lgb_clf`\n",
        "    - оцініть якість моделі `final_lgb_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
        "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (4) цього завдання?"
      ],
      "metadata": {
        "id": "nCnkGD_sEW1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція objective\n",
        "def objective(params, train_inputs, train_targets, val_inputs, val_targets):\n",
        "    # Забезпечення, що num_leaves >= 2^max_depth\n",
        "    num_leaves = int(params['num_leaves'])\n",
        "    max_depth = int(params['max_depth'])\n",
        "    if num_leaves < 2 ** max_depth:\n",
        "        num_leaves = 2 ** max_depth\n",
        "\n",
        "    clf = lgb.LGBMClassifier(\n",
        "        n_estimators=int(params['n_estimators']),\n",
        "        learning_rate=params['learning_rate'],\n",
        "        max_depth=max_depth,\n",
        "        num_leaves=num_leaves,\n",
        "        min_child_weight=params['min_child_weight'],\n",
        "        subsample=params['subsample'],\n",
        "        colsample_bytree=params['colsample_bytree'],\n",
        "        reg_alpha=params['reg_alpha'],\n",
        "        reg_lambda=params['reg_lambda'],\n",
        "        max_bin=int(params['max_bin']),\n",
        "        categorical_feature=params['cat_feature'],\n",
        "        missing=np.nan\n",
        "    )\n",
        "\n",
        "    clf.fit(\n",
        "        train_inputs,\n",
        "        train_targets,\n",
        "        eval_set=[(val_inputs, val_targets)],\n",
        "        eval_metric='auc',\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
        "    )\n",
        "\n",
        "    pred = clf.predict_proba(val_inputs)[:, 1]\n",
        "    auc = roc_auc_score(val_targets, pred)\n",
        "\n",
        "    return {'loss': -auc, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "cfMQKA4D47Rq"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Простір гіперпараметрів\n",
        "param_space = {\n",
        "    'num_leaves': hp.choice('num_leaves', range(31, 151, 10)),\n",
        "    'max_depth': hp.choice('max_depth', range(0, 15, 1)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
        "    'n_estimators': hp.choice('n_estimators', range(50, 501, 50)),\n",
        "    'min_child_weight': hp.uniform('min_child_weight', 1, 10),\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "    'max_bin': hp.choice('max_bin', range(100, 256, 10)),\n",
        "    'cat_feature': hp.choice('cat_feature', [cat_feature_indexes])\n",
        "}\n",
        "\n",
        "# Оптимізація\n",
        "trials = Trials()\n",
        "best_params = fmin(\n",
        "    fn=lambda params: objective(params, train_inputs, train_targets, val_inputs, val_targets),\n",
        "    space=param_space,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=10,\n",
        "    trials=trials\n",
        ")\n",
        "\n",
        "# Перетворення значень гіперпараметрів у кінцеві типи\n",
        "best_params['num_leaves'] = int(best_params['num_leaves'])\n",
        "best_params['max_depth'] = int(best_params['max_depth'])\n",
        "best_params['n_estimators'] = int(best_params['n_estimators'])\n",
        "best_params['max_bin'] = int(best_params['max_bin'])\n",
        "\n",
        "# Забезпечення, що num_leaves >= 2 ** max_depth\n",
        "if best_params['num_leaves'] < 2 ** best_params['max_depth']:\n",
        "    best_params['num_leaves'] = 2 ** best_params['max_depth']\n",
        "\n",
        "print(\"Найкращі гіперпараметри: \", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7pnVw6hX3Vqd",
        "outputId": "acaa8fad-e70f-4ae8-86be-51ff710c83dd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1257\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            " 10%|█         | 1/10 [00:00<00:04,  2.24trial/s, best loss: -0.9217456615680089]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1107\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 10%|█         | 1/10 [00:00<00:04,  2.24trial/s, best loss: -0.9217456615680089]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1606\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 20%|██        | 2/10 [00:01<00:05,  1.43trial/s, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            " 30%|███       | 3/10 [00:02<00:05,  1.36trial/s, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004274 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1802\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 30%|███       | 3/10 [00:02<00:05,  1.36trial/s, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            " 40%|████      | 4/10 [00:04<00:06,  1.14s/trial, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001773 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1457\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 40%|████      | 4/10 [00:04<00:06,  1.14s/trial, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1457\n",
            " 50%|█████     | 5/10 [00:05<00:05,  1.20s/trial, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 50%|█████     | 5/10 [00:05<00:05,  1.20s/trial, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001784 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1706\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 60%|██████    | 6/10 [00:06<00:04,  1.21s/trial, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            " 70%|███████   | 7/10 [00:07<00:02,  1.01trial/s, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008289 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1057\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "                                                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1057\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            " 80%|████████  | 8/10 [00:09<00:02,  1.29s/trial, best loss: -0.9362548871664723]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Warning] categorical_feature is set=10,6,5, categorical_column=5,6,10 will be ignored. Current value: categorical_feature=10,6,5\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1107\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            " 90%|█████████ | 9/10 [00:09<00:01,  1.00s/trial, best loss: -0.9369260580286715]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1873: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1893: UserWarning: categorical_feature in param dict is overridden.\n",
            "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: missing\n",
            "100%|██████████| 10/10 [00:09<00:00,  1.05trial/s, best loss: -0.9369260580286715]\n",
            "Найкращі гіперпараметри:  {'cat_feature': 0, 'colsample_bytree': 0.5399162954612313, 'learning_rate': 0.4344941851042041, 'max_bin': 0, 'max_depth': 2, 'min_child_weight': 4.400358191640906, 'n_estimators': 6, 'num_leaves': 7, 'reg_alpha': 0.26521967262019397, 'reg_lambda': 0.049987308645515816, 'subsample': 0.8505218133966631}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Корекція гіперпараметрів\n",
        "if best_params['n_estimators'] < 10:\n",
        "    best_params['n_estimators'] = 50\n",
        "if best_params['max_bin'] == 0:\n",
        "    best_params['max_bin'] = 255\n",
        "\n",
        "# Створення фінальної моделі з найкращими гіперпараметрами\n",
        "final_lgb_clf = lgb.LGBMClassifier(\n",
        "    num_leaves=best_params['num_leaves'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    min_child_weight=best_params['min_child_weight'],\n",
        "    subsample=best_params['subsample'],\n",
        "    colsample_bytree=best_params['colsample_bytree'],\n",
        "    reg_alpha=best_params['reg_alpha'],\n",
        "    reg_lambda=best_params['reg_lambda'],\n",
        "    max_bin=best_params['max_bin']\n",
        ")\n",
        "\n",
        "# Навчання моделі\n",
        "final_lgb_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "# Оцінка на тренувальній вибірці\n",
        "#train_pred = final_lgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "# train_roc_auc = roc_auc_score(train_targets, train_pred)\n",
        "train_pred_proba = final_lgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "train_pred = (train_pred_proba > 0.5).astype(int)\n",
        "train_roc_auc = roc_auc_score(train_targets, train_pred_proba)\n",
        "\n",
        "# Оцінка на валідаційній вибірці\n",
        "#val_pred = final_lgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "#val_roc_auc = roc_auc_score(val_targets, val_pred)\n",
        "val_pred_proba = final_lgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "val_pred = (val_pred_proba > 0.5).astype(int)\n",
        "val_roc_auc = roc_auc_score(val_targets, val_pred_proba)\n",
        "\n",
        "print(f\"AUROC на тренувальній вибірці: {train_roc_auc}\")\n",
        "print(f\"AUROC на валідаційній вибірці: {val_roc_auc}\")\n",
        "\n",
        "# Виведення звіту класифікації для тренувальної вибірки\n",
        "print(\"Звіт класифікації на тренувальній вибірці:\")\n",
        "print(classification_report(train_targets, train_pred, digits=4))\n",
        "\n",
        "# Виведення звіту класифікації для валідаційної вибірки\n",
        "print(\"Звіт класифікації на валідаційній вибірці:\")\n",
        "print(classification_report(val_targets, val_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqkxCQdw_QlK",
        "outputId": "0847f0e9-ecd7-44ce-c7a4-594f7c2f69fb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1826\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "AUROC на тренувальній вибірці: 0.9530393259206817\n",
            "AUROC на валідаційній вибірці: 0.9366873585293916\n",
            "Звіт класифікації на тренувальній вибірці:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9282    0.9671    0.9473      9558\n",
            "         1.0     0.8462    0.7072    0.7705      2442\n",
            "\n",
            "    accuracy                         0.9143     12000\n",
            "   macro avg     0.8872    0.8372    0.8589     12000\n",
            "weighted avg     0.9115    0.9143    0.9113     12000\n",
            "\n",
            "Звіт класифікації на валідаційній вибірці:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9186    0.9586    0.9382      2390\n",
            "         1.0     0.8043    0.6672    0.7294       610\n",
            "\n",
            "    accuracy                         0.8993      3000\n",
            "   macro avg     0.8615    0.8129    0.8338      3000\n",
            "weighted avg     0.8954    0.8993    0.8957      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загальні висновки:\n",
        "Модель з оптимізованими гіперпараметрами має трохи вищий AUROC як на тренувальній (0.9530 проти 0.9501), так і на валідаційній вибірках (0.9367 проти 0.9355). Це свідчить про кращу здатність моделі 1 розрізняти класи.\n",
        "\n",
        "Обидві моделі показують високі значення precision та recall для класу 0. Для класу 1, модель з оптимізованими гіперпараметрами має трохи кращі показники recall на тренувальній вибірці (0.7072 проти 0.6884) та трохи гірші на валідаційній вибірці (0.6672 проти 0.6590). Значення precision для класу 1 в обох моделях майже однакові.\n",
        "\n",
        "Обидві моделі показують добре збалансовані результати між тренувальною та валідаційною вибірками, що свідчить про відсутність значної переучення (bias) або недостатнього навчання (variance).\n"
      ],
      "metadata": {
        "id": "PJwOTqtcE_4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновок**\n",
        "Модель LightGBM з оптимізованими гіперпараметрами показує трохи кращий результат на валідаційній вибірці порівняно з попередньою моделлю. Значення AUROC, precision, recall та f1-score для класу 1 є трохи кращими у порівнянні з попередньою моделлю, що свідчить про кращу загальну продуктивність моделі з оптимізованими гіперпараметрами."
      ],
      "metadata": {
        "id": "nsC73UWwE2b3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Оберіть модель з експериментів в цьому ДЗ і зробіть новий `submission` на Kaggle та додайте код для цього і скріншот скора на публічному лідерборді.\n",
        "  \n",
        "  **Напишіть коментар, чому ви обрали саме цю модель?**\n",
        "\n",
        "  І я вас вітаю - це останнє завдання з цим набором даних 💪 На цьому етапі корисно проаналізувати, які моделі показали себе найкраще і подумати, чому."
      ],
      "metadata": {
        "id": "XArADR2CG8VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Обраю модель LightGBM після оптимізації гіперпараметрів, оскільки вона показала найкращі результати на валідаційній вибірці з найвищим значенням AUROC та добре збалансованими значеннями precision та recall для обох класів. Ця модель має найкращу загальну продуктивність і демонструє, що оптимізація гіперпараметрів значно покращила її здатність розрізняти класи."
      ],
      "metadata": {
        "id": "GP0ksC0gGMxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Підготовка даних для сабмішну\n",
        "# Завантаження тестових даних\n",
        "test_df = pd.read_csv('./bank-customer-churn-prediction-dlu/test.csv')\n",
        "\n",
        "# Переконайтесь, що тестові дані мають ті ж самі колонки, що й тренувальні дані\n",
        "train_columns = train_inputs.columns\n",
        "for col in train_columns:\n",
        "    if col not in test_df.columns:\n",
        "        test_df[col] = 0  # або будь-яке відповідне значення за замовчуванням\n",
        "\n",
        "# Переконайтесь, що порядок колонок збігається\n",
        "test_inputs = test_df[train_columns]\n",
        "\n",
        "# Перетворення категоріальних колонок у той самий тип, що й у тренувальних даних\n",
        "for col in categorical_columns:\n",
        "    test_inputs[col] = pd.Categorical(test_inputs[col], categories=train_inputs[col].cat.categories)\n",
        "\n",
        "# Прогнозування з використанням фінальної моделі LightGBM\n",
        "test_preds = final_lgb_clf.predict_proba(test_inputs)[:, 1]\n",
        "\n",
        "# Підготовка файлу для сабмішну\n",
        "submission_df = pd.DataFrame({'id': test_df['id'], 'Exited': test_preds})\n",
        "\n",
        "# Збереження оновленого DataFrame у новий CSV файл\n",
        "submission_df.to_csv('drive/MyDrive/Colab Notebooks/data//submission_light_opt.csv', index=False)"
      ],
      "metadata": {
        "id": "0XhuXbIJGMXS"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vsytcGRxG2OR",
        "outputId": "a2b0e719-ca14-48c2-e80d-f04728968615"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  Exited\n",
              "0  15000    0.04\n",
              "1  15001    0.01\n",
              "2  15002    0.05\n",
              "3  15003    0.74\n",
              "4  15004    0.03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0376c63a-9142-4093-97ec-1f29490cab62\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15000</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15001</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15002</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15003</td>\n",
              "      <td>0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15004</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0376c63a-9142-4093-97ec-1f29490cab62')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0376c63a-9142-4093-97ec-1f29490cab62 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0376c63a-9142-4093-97ec-1f29490cab62');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74b9d1ac-e52d-419d-8867-34b103cf02a2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74b9d1ac-e52d-419d-8867-34b103cf02a2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74b9d1ac-e52d-419d-8867-34b103cf02a2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission_df",
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2886,\n        \"min\": 15000,\n        \"max\": 24999,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          21252,\n          19684,\n          16731\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Exited\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3098670539710397,\n        \"min\": 0.0003800806683785734,\n        \"max\": 0.9999050604390748,\n        \"num_unique_values\": 8241,\n        \"samples\": [\n          0.09377468114611778,\n          0.062347086343807236,\n          0.6948059590513703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Wu41FdvHI41M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель Логістичної регресії з поліноміальними ознаками показала кращі результати порівняно з моделлю LightGBM з оптимізованими гіперпараметрами. Це може бути обумовлено кількома факторами:\n",
        "1. Поліноміальні ознаки дозволяють моделі враховувати нелінійні взаємозв'язки між змінними. Це могло допомогти логістичній регресії краще зрозуміти структуру даних, що призвело до кращої продуктивності.\n",
        "2. Обробка даних для моделі логістичної регресії включала генерацію поліноміальних ознак до степені 4, що значно збільшило обсяг інформації, доступної для моделі.\n",
        "3. Логістична регресія з поліноміальними ознаками, ймовірно, показала кращу узагальненість та стабільність на даних тестового набору.\n"
      ],
      "metadata": {
        "id": "t-FkLXwXL4Aa"
      }
    }
  ]
}